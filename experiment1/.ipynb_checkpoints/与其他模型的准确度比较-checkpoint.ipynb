{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-23T13:00:15.995101Z",
     "start_time": "2021-03-23T13:00:15.946233Z"
    }
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 1.60 GiB for an array with shape (429506560,) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-f5fc14730f4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;31m##############################数据集读取########################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAINDATA_LOADPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTRAINLABEL_LOADPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTESTDATA_LOADPATH\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    437\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mformat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen_memmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmmap_mode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 439\u001b[1;33m                 return format.read_array(fid, allow_pickle=allow_pickle,\n\u001b[0m\u001b[0;32m    440\u001b[0m                                          pickle_kwargs=pickle_kwargs)\n\u001b[0;32m    441\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\format.py\u001b[0m in \u001b[0;36mread_array\u001b[1;34m(fp, allow_pickle, pickle_kwargs)\u001b[0m\n\u001b[0;32m    739\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    740\u001b[0m             \u001b[1;31m# We can use the fast fromfile() function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 741\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfromfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    742\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[1;31m# This is not a real file. We have to read it the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 1.60 GiB for an array with shape (429506560,) and data type float32"
     ]
    }
   ],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, utils, backend\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xlrd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config_proto = tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "sess = tf.compat.v1.Session(config=config_proto)\n",
    "set_session(sess)\n",
    "\n",
    "#输入数据\n",
    "INPUT_SIZE = [290, 7]  #[time_steps, input_vector]\n",
    "TIME_STEPS = INPUT_SIZE[0]\n",
    "INPUT_NUM = INPUT_SIZE[1]\n",
    "ENTIRE_INPUT_SIZE = [5, TIME_STEPS, 7]\n",
    "ENTIRE_TIME_STEPS = ENTIRE_INPUT_SIZE[0] #总共时序长度\n",
    "\n",
    "#局部编码器\n",
    "LSTM1_INPUT_SIZE = 58 #局部时间长度\n",
    "LSTM1_SIZE1 = 30\n",
    "LSTM1_SIZE2 = 20\n",
    "LSTM1_DENSE_SIZE = 20\n",
    "\n",
    "#局部解码器\n",
    "LSTM2_SIZE1 = LSTM1_DENSE_SIZE\n",
    "LSTM2_SIZE2 = 30\n",
    "\n",
    "#全局编码器\n",
    "LSTM3_INPUT_SIZE = int(TIME_STEPS/LSTM1_INPUT_SIZE) #全局-局部时间长度，feature由上层定\n",
    "LSTM3_INPUT_FEATURE = int(LSTM1_DENSE_SIZE*2)\n",
    "LSTM3_SIZE1 = 40\n",
    "LSTM3_SIZE2 = 30\n",
    "LSTM3_DENSE_SIZE = 30\n",
    "\n",
    "#全局解码器\n",
    "LSTM4_SIZE1 = LSTM3_DENSE_SIZE\n",
    "LSTM4_SIZE2 = 40\n",
    "\n",
    "#顶层时序决策器\n",
    "LSTM5_INPUT_SIZE =  ENTIRE_INPUT_SIZE[0]\n",
    "LSTM5_SIZE1 = 60\n",
    "LSTM5_SIZE2 = 45\n",
    "LSTM5_DENSE_SIZE = 45\n",
    "\n",
    "#决策器\n",
    "DENSE_SIZE = 600\n",
    "OUTPUT_SIZE = 3\n",
    "\n",
    "#训练信息\n",
    "BATCH_SIZE = 128\n",
    "PREDICTOR_TRAIN_BATCH1 = 15\n",
    "\n",
    "TRAINDATA_LOADPATH = 'tool_wear_data_4/train_data.npy' #训练集数据读取路径\n",
    "TRAINLABEL_LOADPATH = 'tool_wear_data_4/train_label.npy' #训练集标签读取路径\n",
    "TESTDATA_LOADPATH = 'tool_wear_data_4/test_data.npy' #验证集数据读取路径\n",
    "TESTLABEL_LOADPATH =  'tool_wear_data_4/test_label.npy' #验证集标签读取路径\n",
    "SUMMARY_PATH = './logs'     #记录路径\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"# 这一行注释掉就是使用gpu\n",
    "\n",
    "##############################数据集读取########################################\n",
    "X_train=np.load(TRAINDATA_LOADPATH)\n",
    "Y_train=np.load(TRAINLABEL_LOADPATH)\n",
    "X_test=np.load(TESTDATA_LOADPATH)\n",
    "Y_test=np.load(TESTLABEL_LOADPATH)\n",
    "\n",
    "#validation_split将样本集按先后比例分为训练集合样本集，样本数量应为两者和的整数倍\n",
    "X_train = X_train[:(np.shape(X_train)[0]-np.shape(X_train)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_train = Y_train[:(np.shape(Y_train)[0]-np.shape(Y_train)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "X_test = X_test[:(np.shape(X_test)[0]-np.shape(X_test)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_test = Y_test[:(np.shape(Y_test)[0]-np.shape(Y_test)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "\n",
    "print('X_train', np.shape(X_train))\n",
    "\n",
    "\n",
    "###################局部编码器####################################\n",
    "def adjust_range(x):#调整范围，将每一小段的信号都调整至-0.9~0.9\n",
    "    max_val = backend.max(x, axis = 1, keepdims=True)#运算Tensor的第一维都是batch，在axis上取均值，为能够广播运算，必须keepdims\n",
    "    min_val = backend.min(x, axis = 1, keepdims=True)\n",
    "    y = (x - min_val)/(max_val - min_val + 1e-6)*1.8 - 0.9\n",
    "    return y\n",
    "\n",
    "# model各层之间必须用layers连接，如果不是layers必须重新用Input导入\n",
    "input_img = layers.Input(shape=INPUT_SIZE, batch_size=BATCH_SIZE, name = 'input')#input_shape=[time_steps, input_vector]\n",
    "x = layers.Lambda(adjust_range, name = 'adjust_range')(input_img)\n",
    "x = layers.Reshape([LSTM3_INPUT_SIZE, LSTM1_INPUT_SIZE, INPUT_NUM])(x)\n",
    "x = layers.TimeDistributed(layers.LSTM(LSTM1_SIZE1, return_sequences=True))(x)\n",
    "_, local_state_h, local_state_c = layers.TimeDistributed(layers.LSTM(LSTM1_SIZE2, return_sequences=False, return_state=True))(x)\n",
    "local_state_h = layers.TimeDistributed(layers.Dense(LSTM1_DENSE_SIZE, name = 'state_h'))(local_state_h)#[batch, LSTM3_INPUT_SIZE, LSTM1_DENSE_SIZE]\n",
    "local_state_c = layers.TimeDistributed(layers.Dense(LSTM1_DENSE_SIZE, name = 'state_c'))(local_state_c)\n",
    "print('local_state_h', local_state_h)\n",
    "local_encoder = models.Model(inputs=input_img, outputs=[local_state_h, local_state_c], name='local_encoder_model')#局部LSTM编码器\n",
    "\n",
    "###################全局编码器##################################\n",
    "#全局编码器，输入局部编码器的local_state，输出global_state_h, global_state_c\n",
    "def global_encoder_model_construct(name):\n",
    "    global_encoder_input = layers.Input(shape=[LSTM3_INPUT_SIZE, LSTM3_INPUT_FEATURE], \n",
    "                                        batch_size = BATCH_SIZE, name='global_encoder_input')\n",
    "    x = layers.LSTM(LSTM3_SIZE1, return_sequences=True, name='global_encoded_LSTM1')(global_encoder_input)\n",
    "    _, global_state_h, global_state_c = layers.LSTM(LSTM3_SIZE2, return_sequences=False, \n",
    "                                                    return_state=True, name='global_encoded_LSTM2')(x)\n",
    "    global_state_h = layers.Dense(LSTM3_DENSE_SIZE, name = 'global_state_h')(global_state_h)#[batch, LSTM3_INPUT_SIZE, LSTM1_DENSE_SIZE]\n",
    "    print('global_state_h', global_state_h)\n",
    "    global_state_c = layers.Dense(LSTM3_DENSE_SIZE, name = 'global_state_c')(global_state_c)\n",
    "    global_encoder = models.Model(inputs=global_encoder_input, outputs=[global_state_h, global_state_c], name = name)\n",
    "    return global_encoder\n",
    "\n",
    "global_encoder = global_encoder_model_construct('global_encoder_model')#全局LSTM编码器\n",
    "\n",
    "#特征提取网络\n",
    "global_encoder_input_union = layers.Concatenate(axis = 2, name='global_encoder_input_union')([local_state_h, local_state_c])\n",
    "global_state_h, global_state_c = global_encoder(global_encoder_input_union)\n",
    "feature_extracted = layers.Concatenate(axis = 1)([global_state_h, global_state_c])\n",
    "extract_network = models.Model(inputs=input_img, outputs=feature_extracted, name='extract_network')\n",
    "\n",
    "###################顶层编码器##################################\n",
    "#顶层编码器，输入全局编码器的feature1~5，输出feature\n",
    "def top_encoder_model_construct(name):\n",
    "    top_encoder_input = layers.Input(shape=[LSTM5_INPUT_SIZE, LSTM3_DENSE_SIZE*2], \n",
    "                                        batch_size = BATCH_SIZE, name='top_encoder_input')\n",
    "    x = layers.LSTM(LSTM5_SIZE1, return_sequences=True, name='top_encoded_LSTM1')(top_encoder_input)\n",
    "    top_state_h  = layers.LSTM(LSTM5_SIZE2, return_sequences=False, name='top_encoded_LSTM2')(x)\n",
    "    top_state_h = layers.Dense(LSTM5_DENSE_SIZE, name = 'top_state_h')(top_state_h)#[batch, LSTM5_INPUT_SIZE, LSTM1_DENSE_SIZE]\n",
    "    top_encoder = models.Model(inputs=top_encoder_input, outputs=top_state_h, name = name)\n",
    "    return top_encoder\n",
    "top_encoder = top_encoder_model_construct('top_encoder_model')#全局LSTM编码器\n",
    "\n",
    "###################顶层LSTM######################################\n",
    "entire_input = layers.Input(shape=ENTIRE_INPUT_SIZE,  batch_size = BATCH_SIZE, name='entire_input')\n",
    "top_input0 = layers.Lambda(lambda x:x[:, 0, :, :])(entire_input)\n",
    "top_input1 = layers.Lambda(lambda x:x[:, 1, :, :])(entire_input)\n",
    "top_input2 = layers.Lambda(lambda x:x[:, 2, :, :])(entire_input)\n",
    "top_input3 = layers.Lambda(lambda x:x[:, 3, :, :])(entire_input)\n",
    "top_input4 = layers.Lambda(lambda x:x[:, 4, :, :])(entire_input)\n",
    "feature0 = extract_network(top_input0)\n",
    "feature1 = extract_network(top_input1)\n",
    "feature2 = extract_network(top_input2)\n",
    "feature3 = extract_network(top_input3)\n",
    "feature4 = extract_network(top_input4)\n",
    "feature0 = layers.Reshape([1, LSTM3_DENSE_SIZE*2])(feature0)\n",
    "feature1 = layers.Reshape([1, LSTM3_DENSE_SIZE*2])(feature1)\n",
    "feature2 = layers.Reshape([1, LSTM3_DENSE_SIZE*2])(feature2)\n",
    "feature3 = layers.Reshape([1, LSTM3_DENSE_SIZE*2])(feature3)\n",
    "feature4 = layers.Reshape([1, LSTM3_DENSE_SIZE*2])(feature4)\n",
    "feature = layers.Concatenate(axis = 1)([feature0, feature1, feature2, feature3, feature4])#包含sample维度\n",
    "\n",
    "###################决策器######################################\n",
    "# var_input = layers.Lambda(var_input_layer, name = 'var_input_layer')(entire_input)\n",
    "# var_input = layers.Lambda(lambda x:x/10)(var_input)\n",
    "# #var_model = models.Model(inputs=entire_input, outputs=var_input, name='var_input')\n",
    "# top_state_h = top_encoder(feature)\n",
    "# LSTM_encoder = models.Model(inputs=entire_input, outputs=top_state_h, name='LSTM_encoder')\n",
    "# x = layers.Concatenate(axis = 1)([top_state_h, var_input])\n",
    "\n",
    "top_state_h = top_encoder(feature)\n",
    "LSTM_encoder = models.Model(inputs=entire_input, outputs=top_state_h, name='LSTM_encoder')\n",
    "x = layers.Dense(DENSE_SIZE, activation='tanh')(top_state_h)\n",
    "dense_layer1 = models.Model(inputs=entire_input, outputs=x, name='dense_layer1')\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(OUTPUT_SIZE, name='output', activation='tanh')(x)\n",
    "predictor = models.Model(inputs=entire_input, outputs=output, name='predictor_model')\n",
    "print('output', output)\n",
    "\n",
    "#############################################模型训练#########################################################################\n",
    "time_start = time.time()\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.2, min_lr=0.00001, mode='auto')\n",
    "\n",
    "#predictor\n",
    "predictor.compile(optimizer=adam, loss = 'logcosh')\n",
    "\n",
    "#输出的loss表示整体误差，由于decoded和local_decoded用的是同一个模型，误差被整合成了一个\n",
    "history = predictor.fit(X_train, Y_train, validation_data=[X_validation, Y_validation],\n",
    "                         epochs=PREDICTOR_TRAIN_BATCH1, batch_size=BATCH_SIZE, shuffle=True, verbose=1)\n",
    "\n",
    "#for layer in predictor.layers:\n",
    "#    print(layer.name)\n",
    "#    print(predictor.get_layer(layer.name).get_weights())\n",
    "\n",
    "print('time1 =  ', time.time()-time_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
