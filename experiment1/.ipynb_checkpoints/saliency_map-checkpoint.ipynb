{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# saliency map 2021.7.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pywt\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\"    # 这一行注释掉就是使用gpu\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, utils, backend\n",
    "import time\n",
    "\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.compat.v1.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "gpu_options = tf.compat.v1.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "config_proto = tf.compat.v1.ConfigProto(gpu_options=gpu_options)\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off \n",
    "sess = tf.compat.v1.Session(config=config_proto)\n",
    "set_session(sess)\n",
    "\n",
    "MODEL_LOAD_PATH = 'attention_distribution_dataset9/model.h5'\n",
    "MODEL_LOAD_PATH2 = 'attention_distribution_dataset9/model2.h5'\n",
    "\n",
    "\n",
    "load_flag = 1 ########################################1:重新加载模型，0：不加载##########################\n",
    "#输入数据\n",
    "INPUT_SIZE = [2304, 7]  #[time_steps, input_vector]\n",
    "INPUT_NUM = INPUT_SIZE[1]\n",
    "\n",
    "SCALE_NUM_FORCE = 3 #小波分解级数\n",
    "SCALE_NUM_VIBRATION = 3 #小波分解级数\n",
    "SCALE_NUM_AE = 3 #小波分解级数\n",
    "WAVELET_HIGHFREQ = 'db2'\n",
    "WAVELET_LOWFREQ = 'db6'\n",
    "# NOISE_FILTER_PERCENT = 90\n",
    "\n",
    "ATTENTION_RANGE = 48\n",
    "OUTPUT_SIZE = 3\n",
    "BATCH_SIZE = 64\n",
    "size = 15\n",
    "\n",
    "if load_flag == 1:\n",
    "    class lowhigh_freq_Attention(layers.Layer):\n",
    "        # 将query，value和key拼接后输入，dot attention，便于timedistributed\n",
    "        # https://blog.csdn.net/qq_37285386/article/details/101697758\n",
    "        def __init__(self, **kwargs): #初始化方法\n",
    "            super(lowhigh_freq_Attention,self).__init__(**kwargs) #必须要的初始化自定义层\n",
    "        def build(self, input_shape): #为Mylayer建立一个可训练的权重\n",
    "            super(lowhigh_freq_Attention,self).build(input_shape)\n",
    "        def call(self, x): #call函数里就是定义了对x张量的计算图，且x只是一个形式，所以不能被事先定义\n",
    "            query = x[:, 0]\n",
    "            query = tf.expand_dims(query, axis=1)\n",
    "            value = x[:, 1:ATTENTION_RANGE+1]\n",
    "            key = x[:, ATTENTION_RANGE+1:]\n",
    "            scores = tf.matmul(query, key, transpose_b=True)\n",
    "            distribution = tf.nn.softmax(scores, axis = 2)\n",
    "            value = tf.transpose(value, [0, 2, 1])\n",
    "            value_weighted = value * distribution\n",
    "            value_weighted = tf.reduce_sum(value_weighted, axis=2)\n",
    "            attention_distribution = tf.squeeze(distribution)\n",
    "            return value_weighted, attention_distribution\n",
    "        def compute_output_shape(self,input_shape):\n",
    "            return (input_shape[0], input_shape[2]), (input_shape[0], ATTENTION_RANGE) #这里是自己手动计算出来的output_shape\n",
    "\n",
    "    class temporal_Attention(layers.Layer):\n",
    "        # 将query，value和key拼接后输入，dot attention，便于timedistributed\n",
    "        # https://blog.csdn.net/qq_37285386/article/details/101697758\n",
    "        def __init__(self, **kwargs): #初始化方法\n",
    "            super(temporal_Attention,self).__init__(**kwargs) #必须要的初始化自定义层\n",
    "        def build(self, input_shape): #为Mylayer建立一个可训练的权重\n",
    "            self.u_query=self.add_weight(name='u_query',shape=[1, input_shape[2]], trainable=True, initializer='uniform')\n",
    "            super(temporal_Attention,self).build(input_shape)\n",
    "        def call(self, key): #call函数里就是定义了对x张量的计算图，且x只是一个形式，所以不能被事先定义\n",
    "            scores = tf.matmul(self.u_query, key, transpose_b=True)\n",
    "            distribution = tf.nn.softmax(scores, axis = 2)\n",
    "            key = tf.transpose(key, [0, 2, 1])\n",
    "            value_weighted = key * distribution\n",
    "            value_weighted = tf.reduce_sum(value_weighted, axis=2)\n",
    "            attention_distribution = tf.squeeze(distribution)\n",
    "            return value_weighted, attention_distribution\n",
    "        def compute_output_shape(self,input_shape):\n",
    "            return (input_shape[0], input_shape[2]), (input_shape[0], input_shape[1])#这里是自己手动计算出来的output_shape\n",
    "\n",
    "    def wavelet_transform(data, scale_num):\n",
    "        coeffs = np.arange(2).tolist()\n",
    "        for j in range(np.shape(data)[2]):\n",
    "            sample = data[:, :, j].reshape([-1, np.shape(data)[1]])\n",
    "            coeffs_lowfreq = pywt.wavedec(sample, WAVELET_LOWFREQ, 'symmetric', level=scale_num) #低频部分采用消失矩高的小波\n",
    "            coeffs_lowfreq = coeffs_lowfreq[0][:, 7:-2] #低频\n",
    "            coeffs_highfreq = pywt.wavedec(sample, WAVELET_HIGHFREQ, 'symmetric', level=scale_num) #高频部分采用消失矩低的小波\n",
    "            coeffs_highfreq[0] = np.zeros_like(coeffs_highfreq[0])\n",
    "    #         for i in range(1, scale_num+1):       #高频去噪\n",
    "    #             coeffs_highfreq[i] = percentile_compute(coeffs_highfreq[i], NOISE_FILTER_PERCENT)\n",
    "            coeffs_highfreq = pywt.waverec(coeffs_highfreq, WAVELET_HIGHFREQ)\n",
    "\n",
    "            if j == 0:\n",
    "                coeffs[0] = np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])\n",
    "                coeffs[1] = np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])\n",
    "            else:\n",
    "                coeffs[0] = np.concatenate([coeffs[0], np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])], axis = 2)\n",
    "                coeffs[1] = np.concatenate([coeffs[1], np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])], axis = 2)\n",
    "        return coeffs\n",
    "\n",
    "\n",
    "    ################################################### 模型读取及预测 ##################################################\n",
    "    predictor = keras.models.load_model(MODEL_LOAD_PATH, custom_objects={'lowhigh_freq_Attention':lowhigh_freq_Attention, \n",
    "                                                                         'temporal_Attention':temporal_Attention})\n",
    "    att_distribution_model = keras.models.load_model(MODEL_LOAD_PATH2, custom_objects={'lowhigh_freq_Attention':lowhigh_freq_Attention, \n",
    "                                                                                       'temporal_Attention':temporal_Attention})\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
