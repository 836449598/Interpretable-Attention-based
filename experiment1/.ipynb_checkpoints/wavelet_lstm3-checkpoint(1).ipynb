{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 小波变换削减通道+两种母小波+去噪重构+GRU+attention+ hierarchical attention LSTM 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2020-12-29T06:01:22.719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coeffs_lowfreq_train (28480, 256, 7)\n",
      "coeffs_highfreq_train (28480, 2048, 6)\n",
      "coeffs_lowfreq_validation (4288, 256, 7)\n",
      "coeffs_highfreq_validation (4288, 2048, 6)\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Orthogonal.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "feature_freq Tensor(\"concatenate_1/concat:0\", shape=(64, 256, 20), dtype=float32)\n",
      "aaaaaaaa Tensor(\"time_distributed_6/Reshape_1:0\", shape=(64, 16, 16, 50), dtype=float32)\n",
      "aaaaaaaa Tensor(\"time_distributed_7/Reshape_1:0\", shape=(64, 16, 16, 40), dtype=float32)\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "feature_local Tensor(\"biLSTM_local/time_distributed_8/transpose_1:0\", shape=(64, 16, 40), dtype=float32)\n",
      "feature Tensor(\"biLSTM_global/temporal__attention_1/Sum:0\", shape=(64, 45), dtype=float32)\n",
      "att_distribution_global Tensor(\"biLSTM_global/temporal__attention_1/Squeeze:0\", shape=(64, 16), dtype=float32)\n",
      "Model: \"tool_wear_predictor\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_highfreq (InputLayer)     [(64, 2048, 6)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "highfreq_model (Model)          [(64, 2048, 10), (64 2324        input_highfreq[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "input_lowfreq (InputLayer)      [(64, 256, 7)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d (ZeroPadding1D)  (64, 2104, 10)       0           highfreq_model[1][1]             \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding1d_1 (ZeroPadding1D (64, 2104, 10)       0           highfreq_model[1][0]             \n",
      "__________________________________________________________________________________________________\n",
      "lowfreq_model (Model)           [(64, 256, 10), (64, 2420        input_lowfreq[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_1 (Reshape)             (64, 263, 8, 10)     0           zero_padding1d[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "reshape_2 (Reshape)             (64, 263, 8, 10)     0           zero_padding1d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (64, 256, 1, 10)     0           lowfreq_model[1][1]              \n",
      "__________________________________________________________________________________________________\n",
      "splicing_value (Lambda)         (64, 256, 64, 10)    0           reshape_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "splicing_key (Lambda)           (64, 256, 64, 10)    0           reshape_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (64, 256, 129, 10)   0           reshape[0][0]                    \n",
      "                                                                 splicing_value[0][0]             \n",
      "                                                                 splicing_key[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib ((64, 256, 10), (64, 0           concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (64, 256, 20)        0           lowfreq_model[1][0]              \n",
      "                                                                 time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "biLSTM_local (Model)            [(64, 16, 40), (64,  21840       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "biLSTM_global (Model)           [(64, 45), (64, 16)] 35430       biLSTM_local[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (64, 250)            11500       biLSTM_global[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (64, 250)            0           dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (64, 3)              753         dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 74,267\n",
      "Trainable params: 74,267\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\Users\\83644\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 28480 samples, validate on 4288 samples\n",
      "Epoch 1/10\n",
      "28416/28480 [============================>.] - ETA: 1s - loss: 0.0440"
     ]
    }
   ],
   "source": [
    "# 一维离散小波变换\n",
    "# 对不同传感器信号采用不同的小波级数和频带，降低输入通道数 2020.10.24\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, utils, backend\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)\n",
    "\n",
    "TRAINDATA_LOADPATH = 'tool_wear_data_1/train_data.npy' #训练集数据读取路径\n",
    "TRAINLABEL_LOADPATH = 'tool_wear_data_1/train_label.npy' #训练集标签读取路径\n",
    "VALIDATIONDATA_LOADPATH = 'tool_wear_data_1/validation_data.npy' #验证集数据读取路径\n",
    "VALIDATIONLABEL_LOADPATH =  'tool_wear_data_1/validation_label.npy' #验证集标签读取路径\n",
    "TESTDATA_LOADPATH = 'tool_wear_data_1/test_data.npy' #验证集数据读取路径\n",
    "TESTLABEL_LOADPATH =  'tool_wear_data_1/test_label.npy' #验证集标签读取路径\n",
    "SUMMARY_PATH = './logs'     #记录路径\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"# 这一行注释掉就是使用gpu\n",
    "\n",
    "\n",
    "#输入数据\n",
    "INPUT_SIZE = [2048, 7]  #[time_steps, input_vector]\n",
    "INPUT_NUM = INPUT_SIZE[1]\n",
    "\n",
    "SCALE_NUM_FORCE = 3 #小波分解级数\n",
    "SCALE_NUM_VIBRATION = 3 #小波分解级数\n",
    "SCALE_NUM_AE = 3 #小波分解级数\n",
    "WAVELET_HIGHFREQ = 'db2'\n",
    "WAVELET_LOWFREQ = 'db6'\n",
    "# NOISE_FILTER_PERCENT = 90\n",
    "\n",
    "LOWFREQ_INPUT_SIZE = [256, 7]\n",
    "LOWFREQ_LSTM_SIZE = 12\n",
    "LOWFREQ_FEATURE_SIZE = 10\n",
    "ATTENTION_SIZE = 10\n",
    "\n",
    "HIGHFREQ_INPUT_SIZE = [2048, 6]\n",
    "HIGHFREQ_LSTM_SIZE = 12\n",
    "# LOWFREQ_FEATURE_SIZE = ATTENTION_SIZE\n",
    "ATTENTION_RANGE = 64\n",
    "PADDING_LENGTH = int(ATTENTION_RANGE - HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0])\n",
    "\n",
    "LOCAL_INPUT_SIZE = [LOWFREQ_INPUT_SIZE[0], LOWFREQ_FEATURE_SIZE+ATTENTION_SIZE]\n",
    "LOCAL_TIMESTEP = 16\n",
    "LOCAL_LSTM1_SIZE = 20\n",
    "LOCAL_LSTM2_SIZE = 25\n",
    "LOCAL_DENSE_SIZE = 40\n",
    "\n",
    "GLOBAL_INPUT_SIZE = [LOCAL_INPUT_SIZE[0]/LOCAL_TIMESTEP, LOCAL_DENSE_SIZE]\n",
    "GLOBAL_LSTM1_SIZE = 25\n",
    "GLOBAL_LSTM2_SIZE = 30\n",
    "GLOBAL_DENSE_SIZE = 45\n",
    "\n",
    "PREDICT_DENSE_SIZE = 250\n",
    "OUTPUT_SIZE = 3\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PREDICTOR_TRAIN_BATCH = 10\n",
    "\n",
    "sample_index = 3000\n",
    "\n",
    "##############################数据集读取########################################\n",
    "X_train=np.load(TRAINDATA_LOADPATH)\n",
    "Y_train=np.load(TRAINLABEL_LOADPATH)\n",
    "X_validation=np.load(VALIDATIONDATA_LOADPATH)\n",
    "Y_validation=np.load(VALIDATIONLABEL_LOADPATH)\n",
    "\n",
    "#validation_split将样本集按先后比例分为训练集合样本集，样本数量应为两者和的整数倍\n",
    "X_train = X_train[:(np.shape(X_train)[0]-np.shape(X_train)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_train = Y_train[:(np.shape(Y_train)[0]-np.shape(Y_train)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "X_validation = X_validation[:(np.shape(X_validation)[0]-np.shape(X_validation)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_validation = Y_validation[:(np.shape(Y_validation)[0]-np.shape(Y_validation)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "\n",
    "############################################################小波分析##########################################################################################\n",
    "#通过百分数滤除小尺度部分的噪声，输入小波信号整体\n",
    "def percentile_compute(signal, percent): \n",
    "    percentile = np.percentile(np.abs(signal), percent)\n",
    "    signal[np.abs(signal) < percentile] = 0\n",
    "    return signal\n",
    "\n",
    "def wavelet_transform(data, scale_num):\n",
    "    coeffs = np.arange(2).tolist()\n",
    "    for j in range(np.shape(data)[2]):\n",
    "        sample = data[:, :, j].reshape([-1, np.shape(data)[1]])\n",
    "        coeffs_lowfreq = pywt.wavedec(sample, WAVELET_LOWFREQ, 'symmetric', level=scale_num) #低频部分采用消失矩高的小波\n",
    "        coeffs_lowfreq = coeffs_lowfreq[0][:, 7:-2] #低频\n",
    "        coeffs_highfreq = pywt.wavedec(sample, WAVELET_HIGHFREQ, 'symmetric', level=scale_num) #高频部分采用消失矩低的小波\n",
    "        coeffs_highfreq[0] = np.zeros_like(coeffs_highfreq[0])\n",
    "#         for i in range(1, scale_num+1):       #高频去噪\n",
    "#             coeffs_highfreq[i] = percentile_compute(coeffs_highfreq[i], NOISE_FILTER_PERCENT)\n",
    "        coeffs_highfreq = pywt.waverec(coeffs_highfreq, WAVELET_HIGHFREQ)\n",
    "\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(data[sample_index, :1024, j])\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(coeffs_lowfreq[sample_index, :128])\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(coeffs_highfreq[sample_index, :1024])\n",
    "#         plt.show()\n",
    "        \n",
    "        if j == 0:\n",
    "            coeffs[0] = np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])\n",
    "            coeffs[1] = np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])\n",
    "        else:\n",
    "            coeffs[0] = np.concatenate([coeffs[0], np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])], axis = 2)\n",
    "            coeffs[1] = np.concatenate([coeffs[1], np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])], axis = 2)\n",
    "    return coeffs\n",
    "\n",
    "coeffs_train_force = wavelet_transform(X_train[:, :, 0:3], SCALE_NUM_FORCE)\n",
    "coeffs_train_vibration = wavelet_transform(X_train[:, :, 3:6], SCALE_NUM_VIBRATION)\n",
    "coeffs_train_AE = wavelet_transform(X_train[:, :, 6].reshape([np.shape(X_train)[0], np.shape(X_train)[1], 1]), SCALE_NUM_AE)\n",
    "coeffs_train_AE = coeffs_train_AE[0]\n",
    "coeffs_lowfreq_train = np.concatenate([coeffs_train_force[0], coeffs_train_vibration[0], coeffs_train_AE], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "coeffs_highfreq_train = np.concatenate([coeffs_train_force[1], coeffs_train_vibration[1]], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "print('coeffs_lowfreq_train', np.shape(coeffs_lowfreq_train))\n",
    "print('coeffs_highfreq_train', np.shape(coeffs_highfreq_train))\n",
    "\n",
    "coeffs_validation_force = wavelet_transform(X_validation[:, :, 0:3], SCALE_NUM_FORCE)\n",
    "coeffs_validation_vibration = wavelet_transform(X_validation[:, :, 3:6], SCALE_NUM_VIBRATION)\n",
    "coeffs_validation_AE = wavelet_transform(X_validation[:, :, 6].reshape([np.shape(X_validation)[0], np.shape(X_validation)[1], 1]), SCALE_NUM_AE)\n",
    "coeffs_validation_AE = coeffs_validation_AE[0]\n",
    "coeffs_lowfreq_validation = np.concatenate([coeffs_validation_force[0], coeffs_validation_vibration[0], coeffs_validation_AE], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "coeffs_highfreq_validation = np.concatenate([coeffs_validation_force[1], coeffs_validation_vibration[1]], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "print('coeffs_lowfreq_validation', np.shape(coeffs_lowfreq_validation))\n",
    "print('coeffs_highfreq_validation', np.shape(coeffs_highfreq_validation))\n",
    "\n",
    "##############################################################################################频带模型搭建###############################################################\n",
    "def adjust_range(x):#调整范围，将每一小段的信号都调整至-0.9~0.9\n",
    "    max_val = backend.max(x, axis = 1, keepdims=True)#运算Tensor的第一维都是batch，在axis上取均值，为能够广播运算，必须keepdims\n",
    "    min_val = backend.min(x, axis = 1, keepdims=True)\n",
    "    y = (x - min_val)/(max_val - min_val + 1e-6)*1.8 - 0.9\n",
    "    return y\n",
    "def lowfreq_model_construct(input_size, rnn_size, output_size, attention_size, name):\n",
    "# 双层双向GRU提取邻域特征，送入dense层得到low_frequency_feature和query\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='lowfreq_inputs')\n",
    "    x = layers.Lambda(adjust_range, name = 'adjust_range')(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_size, return_sequences=True, name='biLSTM'))(x)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(output_size, activation='tanh'))(x)\n",
    "    query = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    model_lowfreq = models.Model(inputs=inputs, outputs=[outputs, query], name = name)\n",
    "    return model_lowfreq\n",
    "\n",
    "def highfreq_model_construct(input_size, rnn_size, attention_size, name):\n",
    "# 双层双向GRU提取邻域特征，送入dense层得到low_frequency_feature和query\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='highfreq_inputs')\n",
    "    x = layers.Lambda(adjust_range, name = 'adjust_range')(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_size, return_sequences=True, name='biLSTM'))(x)\n",
    "    key = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    value = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    model_highfreq = models.Model(inputs=inputs, outputs=[key, value], name = name)\n",
    "    return model_highfreq\n",
    "\n",
    "def splicing(x):\n",
    "    x0 = x[:, :-7]\n",
    "    x1 = x[:, 1:-6]\n",
    "    x2 = x[:, 2:-5]\n",
    "    x3 = x[:, 3:-4]\n",
    "    x4 = x[:, 4:-3]\n",
    "    x5 = x[:, 5:-2]\n",
    "    x6 = x[:, 6:-1]\n",
    "    x7 = x[:, 7:]\n",
    "    y = backend.concatenate([x0, x1, x2, x3, x4, x5, x6, x7], axis = 2)\n",
    "    return y\n",
    "    \n",
    "class lowhigh_freq_Attention(layers.Layer):\n",
    "    # 将query，value和key拼接后输入，dot attention，便于timedistributed\n",
    "    # https://blog.csdn.net/qq_37285386/article/details/101697758\n",
    "    def __init__(self, **kwargs): #初始化方法\n",
    "        super(lowhigh_freq_Attention,self).__init__(**kwargs) #必须要的初始化自定义层\n",
    "    def build(self, input_shape): #为Mylayer建立一个可训练的权重\n",
    "        super(lowhigh_freq_Attention,self).build(input_shape)\n",
    "    def call(self, x): #call函数里就是定义了对x张量的计算图，且x只是一个形式，所以不能被事先定义\n",
    "        query = x[:, 0]\n",
    "        query = tf.expand_dims(query, axis=1)\n",
    "        value = x[:, 1:ATTENTION_RANGE+1]\n",
    "        key = x[:, ATTENTION_RANGE+1:]\n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        distribution = tf.nn.softmax(scores, axis = 2)\n",
    "        value = tf.transpose(value, [0, 2, 1])\n",
    "        value_weighted = value * distribution\n",
    "        value_weighted = tf.reduce_sum(value_weighted, axis=2)\n",
    "        attention_distribution = tf.squeeze(distribution)\n",
    "        return value_weighted, attention_distribution\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0], input_shape[2]), (input_shape[0], ATTENTION_RANGE) #这里是自己手动计算出来的output_shape\n",
    "    \n",
    "class temporal_Attention(layers.Layer):\n",
    "    # 将query，value和key拼接后输入，dot attention，便于timedistributed\n",
    "    # https://blog.csdn.net/qq_37285386/article/details/101697758\n",
    "    def __init__(self, **kwargs): #初始化方法\n",
    "        super(temporal_Attention,self).__init__(**kwargs) #必须要的初始化自定义层\n",
    "    def build(self, input_shape): #为Mylayer建立一个可训练的权重\n",
    "        self.u_query=self.add_weight(name='u_query',shape=[1, input_shape[2]], trainable=True, initializer='uniform')\n",
    "        super(temporal_Attention,self).build(input_shape)\n",
    "    def call(self, key): #call函数里就是定义了对x张量的计算图，且x只是一个形式，所以不能被事先定义\n",
    "        scores = tf.matmul(self.u_query, key, transpose_b=True)\n",
    "        distribution = tf.nn.softmax(scores, axis = 2)\n",
    "        key = tf.transpose(key, [0, 2, 1])\n",
    "        value_weighted = key * distribution\n",
    "        value_weighted = tf.reduce_sum(value_weighted, axis=2)\n",
    "        attention_distribution = tf.squeeze(distribution)\n",
    "        return value_weighted, attention_distribution\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0], input_shape[2]), (input_shape[0], input_shape[1])#这里是自己手动计算出来的output_shape\n",
    "\n",
    "#高低频时序特征提取\n",
    "input_lowfreq = layers.Input(shape=LOWFREQ_INPUT_SIZE, batch_size = BATCH_SIZE, name='input_lowfreq')\n",
    "input_lowfreq_batch = layers.BatchNormalization(axis=0)(input_lowfreq)\n",
    "input_highfreq = layers.Input(shape=HIGHFREQ_INPUT_SIZE, batch_size = BATCH_SIZE, name='input_highfreq')\n",
    "input_highfreq_batch = layers.BatchNormalization(axis=0)(input_highfreq)\n",
    "model_lowfreq = lowfreq_model_construct(LOWFREQ_INPUT_SIZE, LOWFREQ_LSTM_SIZE, LOWFREQ_FEATURE_SIZE, ATTENTION_SIZE, 'lowfreq_model')\n",
    "model_highfreq = highfreq_model_construct(HIGHFREQ_INPUT_SIZE, HIGHFREQ_LSTM_SIZE, ATTENTION_SIZE, 'highfreq_model')\n",
    "# 低频特征构造query，高频特征构造key和value，构建低频特征向高频特征的注意力模型，使高低频长度一致并对齐\n",
    "feature_lowfreq, query = model_lowfreq(input_lowfreq)\n",
    "key, value = model_highfreq(input_highfreq)\n",
    "\n",
    "#高低频注意力机制\n",
    "query = layers.Reshape([LOWFREQ_INPUT_SIZE[0], 1, ATTENTION_SIZE])(query)\n",
    "value = layers.ZeroPadding1D(padding=int(PADDING_LENGTH/2))(value)#两端补零，使高频点数和低频点数成倍数关系，已检查\n",
    "value = layers.Reshape([-1, int(HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0]), ATTENTION_SIZE])(value)\n",
    "value = layers.Lambda(splicing, name = 'splicing_value')(value)\n",
    "key = layers.ZeroPadding1D(padding=int(PADDING_LENGTH/2))(key)\n",
    "key = layers.Reshape([-1, int(HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0]), ATTENTION_SIZE])(key)\n",
    "key = layers.Lambda(splicing, name = 'splicing_key')(key)\n",
    "concate_vector = layers.Concatenate(axis = 2)([query, value, key])\n",
    "feature_highfreq, att_distribution_lowhigh = layers.TimeDistributed(lowhigh_freq_Attention())(concate_vector)\n",
    "feature_freq = layers.Concatenate(axis = 2)([feature_lowfreq, feature_highfreq])\n",
    "print('feature_freq', feature_freq)\n",
    "\n",
    "###############################################LSTM模型搭建###############################################################\n",
    "def localLSTM_construct(input_size, timestep, lstm1_size, lstm2_size, dense_size, name):\n",
    "# biLSTM model construction\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='input')\n",
    "    x = layers.Reshape([int(input_size[0]/timestep), timestep, input_size[1]])(inputs)\n",
    "    x = layers.TimeDistributed(layers.Bidirectional(layers.LSTM(lstm1_size, return_sequences=True, name='biLSTM1')))(x)\n",
    "    x = layers.TimeDistributed(layers.Bidirectional(layers.LSTM(lstm2_size, return_sequences=True, name='biLSTM2')))(x)\n",
    "    print('aaaaaaaa', x)\n",
    "    x = layers.TimeDistributed(layers.Dense(dense_size, activation='tanh'))(x)\n",
    "    print('aaaaaaaa', x)\n",
    "    outputs, att_distribution_local = layers.TimeDistributed(temporal_Attention())(x)\n",
    "    biLSTM_model = models.Model(inputs=inputs, outputs=[outputs, att_distribution_local], name = name)\n",
    "    return biLSTM_model\n",
    "\n",
    "biLSTM_local = localLSTM_construct(LOCAL_INPUT_SIZE, LOCAL_TIMESTEP, LOCAL_LSTM1_SIZE, LOCAL_LSTM2_SIZE, LOCAL_DENSE_SIZE, 'biLSTM_local')\n",
    "feature_local, att_distribution_local = biLSTM_local(feature_freq)\n",
    "print('feature_local', feature_local)\n",
    "\n",
    "def globalLSTM_construct(input_size, lstm1_size, lstm2_size, dense_size, name):\n",
    "# biLSTM model construction\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='input')\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm1_size, return_sequences=True, name='biLSTM1'))(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm2_size, return_sequences=True, name='biLSTM2'))(x)\n",
    "    x = layers.Dense(dense_size, activation='tanh')(x)\n",
    "    outputs, att_distribution_global = temporal_Attention()(x)\n",
    "    biLSTM_model = models.Model(inputs=inputs, outputs=[outputs, att_distribution_global], name = name)\n",
    "    return biLSTM_model\n",
    "\n",
    "biLSTM_global = globalLSTM_construct(GLOBAL_INPUT_SIZE, GLOBAL_LSTM1_SIZE, GLOBAL_LSTM2_SIZE, GLOBAL_DENSE_SIZE, 'biLSTM_global')\n",
    "feature, att_distribution_global = biLSTM_global(feature_local)\n",
    "print('feature', feature)\n",
    "print('att_distribution_global', att_distribution_global)\n",
    "x = layers.Dense(PREDICT_DENSE_SIZE, activation='tanh')(feature)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(OUTPUT_SIZE, name='output', activation='tanh')(x)\n",
    "predictor = models.Model(inputs=[input_lowfreq, input_highfreq], outputs=output, name='tool_wear_predictor')\n",
    "# print('output', output)\n",
    "att_distribution_model = models.Model(inputs=[input_lowfreq, input_highfreq], \n",
    "                                      outputs=[att_distribution_lowhigh, att_distribution_local, att_distribution_global], \n",
    "                                      name = 'att_distribution_model')\n",
    "\n",
    "sess= tf.Session()\n",
    "predictor.summary()\n",
    "utils.plot_model(predictor, to_file='predictor_model.png')\n",
    "writer = tf.summary.FileWriter(SUMMARY_PATH, sess.graph)\n",
    "writer.close()\n",
    "\n",
    "#############################################模型训练#########################################################################\n",
    "time_start = time.time()\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=0.00001, mode='auto')\n",
    "#predictor\n",
    "predictor.compile(optimizer=adam, loss = 'mse')\n",
    "history = predictor.fit([coeffs_lowfreq_train, coeffs_highfreq_train], Y_train, \n",
    "                        validation_data = [[coeffs_lowfreq_validation, coeffs_highfreq_validation], Y_validation], \n",
    "                        epochs=PREDICTOR_TRAIN_BATCH, batch_size=BATCH_SIZE, shuffle=True, callbacks=[reduce_lr], verbose=1)\n",
    "\n",
    "print('time1 =  ', time.time()-time_start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "size = 35\n",
    "\n",
    "X_test=np.load(TESTDATA_LOADPATH)\n",
    "Y_test=np.load(TESTLABEL_LOADPATH)\n",
    "X_test = X_test[:(np.shape(X_test)[0]-np.shape(X_test)[0]%BATCH_SIZE),:, :INPUT_NUM]\n",
    "Y_test = Y_test[:(np.shape(Y_test)[0]-np.shape(Y_test)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "print('X_test', np.shape(X_test))\n",
    "print('Y_test', np.shape(Y_test))\n",
    "\n",
    "coeffs_test_force = wavelet_transform(X_test[:, :, 0:3], SCALE_NUM_FORCE)\n",
    "coeffs_test_vibration = wavelet_transform(X_test[:, :, 3:6], SCALE_NUM_VIBRATION)\n",
    "coeffs_test_AE = wavelet_transform(X_test[:, :, 6].reshape([np.shape(X_test)[0], np.shape(X_test)[1], 1]), SCALE_NUM_AE)\n",
    "coeffs_test_AE = coeffs_test_AE[0]\n",
    "coeffs_lowfreq_test = np.concatenate([coeffs_test_force[0], coeffs_test_vibration[0], coeffs_test_AE], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "coeffs_highfreq_test = np.concatenate([coeffs_test_force[1], coeffs_test_vibration[1]], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "print('coeffs_lowfreq_test', np.shape(coeffs_lowfreq_test))\n",
    "print('coeffs_highfreq_test', np.shape(coeffs_highfreq_test))\n",
    "\n",
    "#画图，输出训练和测试曲线\n",
    "Y_pre_train = predictor.predict([coeffs_lowfreq_train, coeffs_highfreq_train])\n",
    "# print('loss_train', predictor.metrics_names[0], score)\n",
    "\n",
    "v = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "result = [np.convolve(Y_pre_train[:, 0], v, mode='same'), np.convolve(Y_pre_train[:, 1], v, mode='same'), \n",
    "          np.convolve(Y_pre_train[:, 2], v, mode='same')]\n",
    "result = np.transpose(result)\n",
    "\n",
    "axis = np.linspace(1, 628, np.shape(result)[0])\n",
    "print('loss_train_avg', np.mean(np.square(result - Y_train)))\n",
    "print('percent_train_avg', np.mean(np.abs(result - Y_train)/Y_train)*100, '%')\n",
    "print('percent_train_avg[0]', np.mean(np.abs(result[:, 0] - Y_train[:, 0])/Y_train[:, 0])*100, '%')\n",
    "print('percent_train_avg[1]', np.mean(np.abs(result[:, 1] - Y_train[:, 1])/Y_train[:, 1])*100, '%')\n",
    "print('percent_train_avg[2]', np.mean(np.abs(result[:, 2] - Y_train[:, 2])/Y_train[:, 2])*100, '%')\n",
    "\n",
    "fig_x = 20\n",
    "fig_y = 10\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.subplots_adjust(wspace=0, hspace=0)\n",
    "font1 = {'family':'Times New Roman', 'weight':'normal', 'size':25}\n",
    "\n",
    "for i in range(3):\n",
    "    fig = plt.subplot(3,2,2*i+1)\n",
    "#     fig.xaxis.set_major_locator(ticker.MultipleLocator(3))\n",
    "    if i == 0:\n",
    "        plt.plot(axis[10:-10], result[10:-10, i],color = 'darkgray', marker = ',', label = 'predicted result')\n",
    "        plt.plot(axis[10:-10], Y_train[10:-10, i],'k',marker = ',',label = 'actual tool wear')\n",
    "#         plt.legend(loc= 2, prop = font1)\n",
    "        plt.xticks([])\n",
    "    if i == 1:\n",
    "        plt.plot(axis[10:-10], result[10:-10, i],color = 'darkgray', marker = ',')\n",
    "        plt.plot(axis[10:-10], Y_train[10:-10, i],'k',marker = ',')\n",
    "        plt.xticks([])\n",
    "        plt.ylabel('tool wear', fontproperties = 'Times New Roman', size = size)\n",
    "    if i == 2:\n",
    "        plt.plot(axis[10:-10], result[10:-10, i],color = 'darkgray', marker = ',')\n",
    "        plt.plot(axis[10:-10], Y_train[10:-10, i],'k',marker = ',')\n",
    "        plt.xticks(fontproperties = 'Times New Roman', size = size)\n",
    "#         plt.xlabel('cutting number', fontproperties = 'Times New Roman', size = 20)\n",
    "    plt.yticks([0.2, 0.5, 0.8], fontproperties = 'Times New Roman', size = size)\n",
    "    \n",
    "    \n",
    "score = predictor.evaluate([coeffs_lowfreq_test, coeffs_highfreq_test], Y_test, verbose=0)\n",
    "Y_pre_test = predictor.predict([coeffs_lowfreq_test, coeffs_highfreq_test])\n",
    "\n",
    "v = [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
    "result = [np.convolve(Y_pre_test[:, 0], v, mode='same'), np.convolve(Y_pre_test[:, 1], v, mode='same'), \n",
    "          np.convolve(Y_pre_test[:, 2], v, mode='same')]\n",
    "result = np.transpose(result)\n",
    "\n",
    "axis = np.linspace(1, 314, np.shape(result)[0])\n",
    "print('loss_test_avg', np.mean(np.square(result - Y_test)))\n",
    "print('percent_test_avg', np.mean(np.abs(result - Y_test)/Y_test)*100, '%')\n",
    "print('percent_test_avg[0]', np.mean(np.abs(result[:, 0] - Y_test[:, 0])/Y_test[:, 0])*100, '%')\n",
    "print('percent_test_avg[1]', np.mean(np.abs(result[:, 1] - Y_test[:, 1])/Y_test[:, 1])*100, '%')\n",
    "print('percent_test_avg[2]', np.mean(np.abs(result[:, 2] - Y_test[:, 2])/Y_test[:, 2])*100, '%')\n",
    "\n",
    "for i in range(3):\n",
    "    plt.subplot(3,2,2*i+2)\n",
    "    plt.plot(axis[10:-10], result[10:-10, i],color = 'darkgray', marker = ',', label = 'predicted result')\n",
    "    plt.plot(axis[10:-10], Y_test[10:-10, i],'k',marker = ',',label = 'actual tool wear')\n",
    "#     plt.yticks([])\n",
    "    if i == 0:\n",
    "        plt.legend(loc= 2, prop = font1)\n",
    "    if i == 2:\n",
    "        plt.xticks(fontproperties = 'Times New Roman', size = size)\n",
    "    else:\n",
    "        plt.xticks([])\n",
    "\n",
    "plt.xlabel('cutting number', fontproperties = 'Times New Roman', size = size)\n",
    "plt.savefig('test_train_output.png', dpi = 300)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#注意力权重显示\n",
    "sample_index = 1000\n",
    "\n",
    "att_distribution_value_lowhigh, att_distribution_value_local, att_distribution_value_global = att_distribution_model.predict(\n",
    "    [coeffs_lowfreq_test[sample_index:sample_index+64], coeffs_highfreq_train[sample_index:sample_index+64]])\n",
    "\n",
    "print('coeffs_lowfreq_test', np.shape(coeffs_lowfreq_test[sample_index]))\n",
    "print('coeffs_highfreq_test', np.shape(coeffs_highfreq_test[sample_index]))\n",
    "print('att_distribution_value_lowhigh', np.shape(att_distribution_value_lowhigh))\n",
    "print('att_distribution_value_local', np.shape(att_distribution_value_local))\n",
    "print('att_distribution_value_global', np.shape(att_distribution_value_global))\n",
    "\n",
    "plot_x = 300\n",
    "plot_y = 50\n",
    "fig_x = 64\n",
    "fig_y = 5\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.plot(coeffs_lowfreq_test[sample_index,:plot_y, :])\n",
    "plt.show()\n",
    "fig_x = 64\n",
    "fig_y = 5\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.plot(coeffs_highfreq_test[sample_index,:plot_x, :])\n",
    "plt.show()\n",
    "\n",
    "fig_x = 25.6*3\n",
    "fig_y = 6.4*3\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.imshow(att_distribution_value_lowhigh[0], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "fig_x = 25.6*3\n",
    "fig_y = 6.4*3\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.imshow(att_distribution_value_local[0], cmap='gray')\n",
    "plt.show()\n",
    "fig_x = 25\n",
    "fig_y = 1\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "plt.imshow([att_distribution_value_global[0]], cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "att_distribution_value_global = np.reshape(att_distribution_value_global, \n",
    "                                           [np.shape(att_distribution_value_global)[0], 1, np.shape(att_distribution_value_global)[1]])\n",
    "print('att_distribution_value_global', np.shape(att_distribution_value_global))\n",
    "att_distribution_value_local = np.transpose(att_distribution_value_local, [0, 2, 1])\n",
    "att_distribution_value_local = att_distribution_value_local*att_distribution_value_global\n",
    "att_distribution_value_local = np.transpose(att_distribution_value_local, [0, 2, 1])\n",
    "print('att_distribution_value_local', np.shape(att_distribution_value_local))\n",
    "\n",
    "att_distribution_value_local = np.reshape(att_distribution_value_local, [np.shape(att_distribution_value_local)[0], -1])\n",
    "print('att_distribution_value_local', np.shape(att_distribution_value_local))\n",
    "att_distribution_value_lowhigh = np.transpose(att_distribution_value_lowhigh, [0, 2, 1])\n",
    "att_distribution_value_lowhigh = att_distribution_value_lowhigh*att_distribution_value_local\n",
    "att_distribution_value_lowhigh = np.transpose(att_distribution_value_lowhigh, [0, 2, 1])\n",
    "\n",
    "weight_matric = np.zeros([256, 2048+64])\n",
    "for i in range(0, 256):\n",
    "    weight_matric[i, 8*i:8*i+64] = att_distribution_value_lowhigh[0, i, :]\n",
    "fig_x = 25\n",
    "fig_y = 150\n",
    "plt.figure(figsize=(fig_x, fig_y))\n",
    "# plt.imshow(weight_matric[0:plot_y, 0:plot_y], cmap='gray')\n",
    "plt.imshow(weight_matric, cmap='gray')\n",
    "# plt.savefig('weight_matric.png', dpi = 300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 无attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 一维离散小波变换\n",
    "# 对不同传感器信号采用不同的小波级数和频带，降低输入通道数 2020.10.24\n",
    "\n",
    "import pywt\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import models, layers, utils, backend\n",
    "import time\n",
    "import os\n",
    "\n",
    "from tensorflow.core.protobuf import rewriter_config_pb2\n",
    "from tensorflow.keras.backend import set_session\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "config_proto = tf.ConfigProto()\n",
    "off = rewriter_config_pb2.RewriterConfig.OFF\n",
    "config_proto.graph_options.rewrite_options.arithmetic_optimization = off\n",
    "session = tf.Session(config=config_proto)\n",
    "set_session(session)\n",
    "\n",
    "TRAINDATA_LOADPATH = 'tool_wear_data_1/train_data.npy' #训练集数据读取路径\n",
    "TRAINLABEL_LOADPATH = 'tool_wear_data_1/train_label.npy' #训练集标签读取路径\n",
    "VALIDATIONDATA_LOADPATH = 'tool_wear_data_1/validation_data.npy' #验证集数据读取路径\n",
    "VALIDATIONLABEL_LOADPATH =  'tool_wear_data_1/validation_label.npy' #验证集标签读取路径\n",
    "TESTDATA_LOADPATH = 'tool_wear_data_1/test_data.npy' #验证集数据读取路径\n",
    "TESTLABEL_LOADPATH =  'tool_wear_data_1/test_label.npy' #验证集标签读取路径\n",
    "SUMMARY_PATH = './logs'     #记录路径\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"# 这一行注释掉就是使用gpu\n",
    "\n",
    "\n",
    "#输入数据\n",
    "INPUT_SIZE = [2048, 7]  #[time_steps, input_vector]\n",
    "INPUT_NUM = INPUT_SIZE[1]\n",
    "\n",
    "SCALE_NUM_FORCE = 3 #小波分解级数\n",
    "SCALE_NUM_VIBRATION = 3 #小波分解级数\n",
    "SCALE_NUM_AE = 3 #小波分解级数\n",
    "WAVELET_HIGHFREQ = 'db2'\n",
    "WAVELET_LOWFREQ = 'db6'\n",
    "# NOISE_FILTER_PERCENT = 90\n",
    "\n",
    "LOWFREQ_INPUT_SIZE = [256, 7]\n",
    "LOWFREQ_LSTM_SIZE = 12\n",
    "LOWFREQ_FEATURE_SIZE = 10\n",
    "ATTENTION_SIZE = 10\n",
    "\n",
    "HIGHFREQ_INPUT_SIZE = [2048, 6]\n",
    "HIGHFREQ_LSTM_SIZE = 12\n",
    "# LOWFREQ_FEATURE_SIZE = ATTENTION_SIZE\n",
    "ATTENTION_RANGE = 64\n",
    "PADDING_LENGTH = int(ATTENTION_RANGE - HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0])\n",
    "\n",
    "LOCAL_INPUT_SIZE = [LOWFREQ_INPUT_SIZE[0], LOWFREQ_FEATURE_SIZE+ATTENTION_SIZE]\n",
    "LOCAL_TIMESTEP = 16\n",
    "LOCAL_LSTM1_SIZE = 20\n",
    "LOCAL_LSTM2_SIZE = 25\n",
    "LOCAL_DENSE_SIZE = 40\n",
    "\n",
    "GLOBAL_INPUT_SIZE = [LOCAL_INPUT_SIZE[0]/LOCAL_TIMESTEP, LOCAL_DENSE_SIZE]\n",
    "GLOBAL_LSTM1_SIZE = 25\n",
    "GLOBAL_LSTM2_SIZE = 30\n",
    "GLOBAL_DENSE_SIZE = 45\n",
    "\n",
    "PREDICT_DENSE_SIZE = 250\n",
    "OUTPUT_SIZE = 3\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "PREDICTOR_TRAIN_BATCH = 10\n",
    "\n",
    "sample_index = 3000\n",
    "\n",
    "##############################数据集读取########################################\n",
    "X_train=np.load(TRAINDATA_LOADPATH)\n",
    "Y_train=np.load(TRAINLABEL_LOADPATH)\n",
    "X_validation=np.load(VALIDATIONDATA_LOADPATH)\n",
    "Y_validation=np.load(VALIDATIONLABEL_LOADPATH)\n",
    "\n",
    "#validation_split将样本集按先后比例分为训练集合样本集，样本数量应为两者和的整数倍\n",
    "X_train = X_train[:(np.shape(X_train)[0]-np.shape(X_train)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_train = Y_train[:(np.shape(Y_train)[0]-np.shape(Y_train)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "X_validation = X_validation[:(np.shape(X_validation)[0]-np.shape(X_validation)[0]%BATCH_SIZE), :,:INPUT_NUM]\n",
    "Y_validation = Y_validation[:(np.shape(Y_validation)[0]-np.shape(Y_validation)[0]%BATCH_SIZE), :OUTPUT_SIZE]\n",
    "\n",
    "############################################################小波分析##########################################################################################\n",
    "#通过百分数滤除小尺度部分的噪声，输入小波信号整体\n",
    "def percentile_compute(signal, percent): \n",
    "    percentile = np.percentile(np.abs(signal), percent)\n",
    "    signal[np.abs(signal) < percentile] = 0\n",
    "    return signal\n",
    "\n",
    "def wavelet_transform(data, scale_num):\n",
    "    coeffs = np.arange(2).tolist()\n",
    "    for j in range(np.shape(data)[2]):\n",
    "        sample = data[:, :, j].reshape([-1, np.shape(data)[1]])\n",
    "        coeffs_lowfreq = pywt.wavedec(sample, WAVELET_LOWFREQ, 'symmetric', level=scale_num) #低频部分采用消失矩高的小波\n",
    "        coeffs_lowfreq = coeffs_lowfreq[0][:, 7:-2] #低频\n",
    "        coeffs_highfreq = pywt.wavedec(sample, WAVELET_HIGHFREQ, 'symmetric', level=scale_num) #高频部分采用消失矩低的小波\n",
    "        coeffs_highfreq[0] = np.zeros_like(coeffs_highfreq[0])\n",
    "#         for i in range(1, scale_num+1):       #高频去噪\n",
    "#             coeffs_highfreq[i] = percentile_compute(coeffs_highfreq[i], NOISE_FILTER_PERCENT)\n",
    "        coeffs_highfreq = pywt.waverec(coeffs_highfreq, WAVELET_HIGHFREQ)\n",
    "\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(data[sample_index, :1024, j])\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(coeffs_lowfreq[sample_index, :128])\n",
    "#         plt.show()\n",
    "#         plt.figure(figsize=(30,2))\n",
    "#         plt.plot(coeffs_highfreq[sample_index, :1024])\n",
    "#         plt.show()\n",
    "        \n",
    "        if j == 0:\n",
    "            coeffs[0] = np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])\n",
    "            coeffs[1] = np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])\n",
    "        else:\n",
    "            coeffs[0] = np.concatenate([coeffs[0], np.array(coeffs_lowfreq).reshape([np.shape(coeffs_lowfreq)[0], np.shape(coeffs_lowfreq)[1], 1])], axis = 2)\n",
    "            coeffs[1] = np.concatenate([coeffs[1], np.array(coeffs_highfreq).reshape([np.shape(coeffs_highfreq)[0], np.shape(coeffs_highfreq)[1], 1])], axis = 2)\n",
    "    return coeffs\n",
    "\n",
    "coeffs_train_force = wavelet_transform(X_train[:, :, 0:3], SCALE_NUM_FORCE)\n",
    "coeffs_train_vibration = wavelet_transform(X_train[:, :, 3:6], SCALE_NUM_VIBRATION)\n",
    "coeffs_train_AE = wavelet_transform(X_train[:, :, 6].reshape([np.shape(X_train)[0], np.shape(X_train)[1], 1]), SCALE_NUM_AE)\n",
    "coeffs_train_AE = coeffs_train_AE[0]\n",
    "coeffs_lowfreq_train = np.concatenate([coeffs_train_force[0], coeffs_train_vibration[0], coeffs_train_AE], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "coeffs_highfreq_train = np.concatenate([coeffs_train_force[1], coeffs_train_vibration[1]], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "print('coeffs_lowfreq_train', np.shape(coeffs_lowfreq_train))\n",
    "print('coeffs_highfreq_train', np.shape(coeffs_highfreq_train))\n",
    "\n",
    "coeffs_validation_force = wavelet_transform(X_validation[:, :, 0:3], SCALE_NUM_FORCE)\n",
    "coeffs_validation_vibration = wavelet_transform(X_validation[:, :, 3:6], SCALE_NUM_VIBRATION)\n",
    "coeffs_validation_AE = wavelet_transform(X_validation[:, :, 6].reshape([np.shape(X_validation)[0], np.shape(X_validation)[1], 1]), SCALE_NUM_AE)\n",
    "coeffs_validation_AE = coeffs_validation_AE[0]\n",
    "coeffs_lowfreq_validation = np.concatenate([coeffs_validation_force[0], coeffs_validation_vibration[0], coeffs_validation_AE], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "coeffs_highfreq_validation = np.concatenate([coeffs_validation_force[1], coeffs_validation_vibration[1]], axis = 2)#将不同尺度的小波系数降采样为同一长度\n",
    "print('coeffs_lowfreq_validation', np.shape(coeffs_lowfreq_validation))\n",
    "print('coeffs_highfreq_validation', np.shape(coeffs_highfreq_validation))\n",
    "\n",
    "##############################################################################################频带模型搭建###############################################################\n",
    "def adjust_range(x):#调整范围，将每一小段的信号都调整至-0.9~0.9\n",
    "    max_val = backend.max(x, axis = 1, keepdims=True)#运算Tensor的第一维都是batch，在axis上取均值，为能够广播运算，必须keepdims\n",
    "    min_val = backend.min(x, axis = 1, keepdims=True)\n",
    "    y = (x - min_val)/(max_val - min_val + 1e-6)*1.8 - 0.9\n",
    "    return y\n",
    "def lowfreq_model_construct(input_size, rnn_size, output_size, attention_size, name):\n",
    "# 双层双向GRU提取邻域特征，送入dense层得到low_frequency_feature和query\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='lowfreq_inputs')\n",
    "    x = layers.Lambda(adjust_range, name = 'adjust_range')(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_size, return_sequences=True, name='biLSTM'))(x)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(output_size, activation='tanh'))(x)\n",
    "    query = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    model_lowfreq = models.Model(inputs=inputs, outputs=[outputs, query], name = name)\n",
    "    return model_lowfreq\n",
    "\n",
    "def highfreq_model_construct(input_size, rnn_size, attention_size, name):\n",
    "# 双层双向GRU提取邻域特征，送入dense层得到low_frequency_feature和query\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='highfreq_inputs')\n",
    "    x = layers.Lambda(adjust_range, name = 'adjust_range')(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(rnn_size, return_sequences=True, name='biLSTM'))(x)\n",
    "    key = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    value = layers.TimeDistributed(layers.Dense(attention_size, activation='tanh'))(x)\n",
    "    model_highfreq = models.Model(inputs=inputs, outputs=[key, value], name = name)\n",
    "    return model_highfreq\n",
    "\n",
    "def splicing(x):\n",
    "    x0 = x[:, :-7]\n",
    "    x1 = x[:, 1:-6]\n",
    "    x2 = x[:, 2:-5]\n",
    "    x3 = x[:, 3:-4]\n",
    "    x4 = x[:, 4:-3]\n",
    "    x5 = x[:, 5:-2]\n",
    "    x6 = x[:, 6:-1]\n",
    "    x7 = x[:, 7:]\n",
    "    y = backend.concatenate([x0, x1, x2, x3, x4, x5, x6, x7], axis = 2)\n",
    "    return y\n",
    "    \n",
    "class lowhigh_freq_Attention(layers.Layer):\n",
    "    # 将query，value和key拼接后输入，dot attention，便于timedistributed\n",
    "    # https://blog.csdn.net/qq_37285386/article/details/101697758\n",
    "    def __init__(self, **kwargs): #初始化方法\n",
    "        super(lowhigh_freq_Attention,self).__init__(**kwargs) #必须要的初始化自定义层\n",
    "    def build(self, input_shape): #为Mylayer建立一个可训练的权重\n",
    "        super(lowhigh_freq_Attention,self).build(input_shape)\n",
    "    def call(self, x): #call函数里就是定义了对x张量的计算图，且x只是一个形式，所以不能被事先定义\n",
    "        query = x[:, 0]\n",
    "        query = tf.expand_dims(query, axis=1)\n",
    "        value = x[:, 1:ATTENTION_RANGE+1]\n",
    "        key = x[:, ATTENTION_RANGE+1:]\n",
    "        scores = tf.matmul(query, key, transpose_b=True)\n",
    "        distribution = tf.nn.softmax(scores, axis = 2)\n",
    "        value = tf.transpose(value, [0, 2, 1])\n",
    "        value_weighted = value * distribution\n",
    "        value_weighted = tf.reduce_sum(value_weighted, axis=2)\n",
    "        attention_distribution = tf.squeeze(distribution)\n",
    "        return value_weighted, attention_distribution\n",
    "    def compute_output_shape(self,input_shape):\n",
    "        return (input_shape[0], input_shape[2]), (input_shape[0], ATTENTION_RANGE) #这里是自己手动计算出来的output_shape\n",
    "\n",
    "#高低频时序特征提取\n",
    "input_lowfreq = layers.Input(shape=LOWFREQ_INPUT_SIZE, batch_size = BATCH_SIZE, name='input_lowfreq')\n",
    "input_lowfreq_batch = layers.BatchNormalization(axis=0)(input_lowfreq)\n",
    "input_highfreq = layers.Input(shape=HIGHFREQ_INPUT_SIZE, batch_size = BATCH_SIZE, name='input_highfreq')\n",
    "input_highfreq_batch = layers.BatchNormalization(axis=0)(input_highfreq)\n",
    "model_lowfreq = lowfreq_model_construct(LOWFREQ_INPUT_SIZE, LOWFREQ_LSTM_SIZE, LOWFREQ_FEATURE_SIZE, ATTENTION_SIZE, 'lowfreq_model')\n",
    "model_highfreq = highfreq_model_construct(HIGHFREQ_INPUT_SIZE, HIGHFREQ_LSTM_SIZE, ATTENTION_SIZE, 'highfreq_model')\n",
    "# 低频特征构造query，高频特征构造key和value，构建低频特征向高频特征的注意力模型，使高低频长度一致并对齐\n",
    "feature_lowfreq, query = model_lowfreq(input_lowfreq)\n",
    "key, value = model_highfreq(input_highfreq)\n",
    "\n",
    "#高低频注意力机制\n",
    "query = layers.Reshape([LOWFREQ_INPUT_SIZE[0], 1, ATTENTION_SIZE])(query)\n",
    "value = layers.ZeroPadding1D(padding=int(PADDING_LENGTH/2))(value)#两端补零，使高频点数和低频点数成倍数关系，已检查\n",
    "value = layers.Reshape([-1, int(HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0]), ATTENTION_SIZE])(value)\n",
    "value = layers.Lambda(splicing, name = 'splicing_value')(value)\n",
    "key = layers.ZeroPadding1D(padding=int(PADDING_LENGTH/2))(key)\n",
    "key = layers.Reshape([-1, int(HIGHFREQ_INPUT_SIZE[0]/LOWFREQ_INPUT_SIZE[0]), ATTENTION_SIZE])(key)\n",
    "key = layers.Lambda(splicing, name = 'splicing_key')(key)\n",
    "concate_vector = layers.Concatenate(axis = 2)([query, value, key])\n",
    "feature_highfreq, att_distribution_lowhigh = layers.TimeDistributed(lowhigh_freq_Attention())(concate_vector)\n",
    "feature_freq = layers.Concatenate(axis = 2)([feature_lowfreq, feature_highfreq])\n",
    "print('feature_freq', feature_freq)\n",
    "\n",
    "###############################################LSTM模型搭建###############################################################\n",
    "def localLSTM_construct(input_size, timestep, lstm1_size, lstm2_size, dense_size, name):\n",
    "# biLSTM model construction\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='input')\n",
    "    x = layers.Reshape([int(input_size[0]/timestep), timestep, input_size[1]])(inputs)\n",
    "    x = layers.TimeDistributed(layers.Bidirectional(layers.LSTM(lstm1_size, return_sequences=True, name='biLSTM1')))(x)\n",
    "    x = layers.TimeDistributed(layers.Bidirectional(layers.LSTM(lstm2_size, return_sequences=True, name='biLSTM2')))(x)\n",
    "    outputs = layers.TimeDistributed(layers.Dense(dense_size, activation='tanh'))(x)\n",
    "    biLSTM_model = models.Model(inputs=inputs, outputs=outputs, name = name)\n",
    "    return biLSTM_model\n",
    "\n",
    "biLSTM_local = localLSTM_construct(LOCAL_INPUT_SIZE, LOCAL_TIMESTEP, LOCAL_LSTM1_SIZE, LOCAL_LSTM2_SIZE, LOCAL_DENSE_SIZE, 'biLSTM_local')\n",
    "feature_local, att_distribution_local = biLSTM_local(feature_freq)\n",
    "print('feature_local', feature_local)\n",
    "\n",
    "def globalLSTM_construct(input_size, lstm1_size, lstm2_size, dense_size, name):\n",
    "# biLSTM model construction\n",
    "    inputs = layers.Input(shape=input_size, batch_size = BATCH_SIZE, name='input')\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm1_size, return_sequences=True, name='biLSTM1'))(inputs)\n",
    "    x = layers.Bidirectional(layers.LSTM(lstm2_size, return_sequences=True, name='biLSTM2'))(x)\n",
    "    outputs = layers.Dense(dense_size, activation='tanh')(x)\n",
    "    biLSTM_model = models.Model(inputs=inputs, outputs=outputs, name = name)\n",
    "    return biLSTM_model\n",
    "\n",
    "biLSTM_global = globalLSTM_construct(GLOBAL_INPUT_SIZE, GLOBAL_LSTM1_SIZE, GLOBAL_LSTM2_SIZE, GLOBAL_DENSE_SIZE, 'biLSTM_global')\n",
    "feature, att_distribution_global = biLSTM_global(feature_local)\n",
    "print('feature', feature)\n",
    "print('att_distribution_global', att_distribution_global)\n",
    "x = layers.Dense(PREDICT_DENSE_SIZE, activation='tanh')(feature)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "output = layers.Dense(OUTPUT_SIZE, name='output', activation='tanh')(x)\n",
    "predictor = models.Model(inputs=[input_lowfreq, input_highfreq], outputs=output, name='tool_wear_predictor')\n",
    "# print('output', output)\n",
    "att_distribution_model = models.Model(inputs=[input_lowfreq, input_highfreq], \n",
    "                                      outputs=[att_distribution_lowhigh, att_distribution_local, att_distribution_global], \n",
    "                                      name = 'att_distribution_model')\n",
    "\n",
    "sess= tf.Session()\n",
    "predictor.summary()\n",
    "utils.plot_model(predictor, to_file='predictor_model.png')\n",
    "writer = tf.summary.FileWriter(SUMMARY_PATH, sess.graph)\n",
    "writer.close()\n",
    "\n",
    "#############################################模型训练#########################################################################\n",
    "time_start = time.time()\n",
    "\n",
    "adam = keras.optimizers.Adam(lr=0.0001)\n",
    "reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, min_lr=0.00001, mode='auto')\n",
    "#predictor\n",
    "predictor.compile(optimizer=adam, loss = 'mse')\n",
    "history = predictor.fit([coeffs_lowfreq_train, coeffs_highfreq_train], Y_train, \n",
    "                        validation_data = [[coeffs_lowfreq_validation, coeffs_highfreq_validation], Y_validation], \n",
    "                        epochs=PREDICTOR_TRAIN_BATCH, batch_size=BATCH_SIZE, shuffle=True, callbacks=[reduce_lr], verbose=1)\n",
    "\n",
    "print('time1 =  ', time.time()-time_start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
